{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb2848a-b225-4bd3-8ab4-7933236ad465",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color:lightgreen; font-size:30px\">**PG102 - Análisis de datos en Geología**</span>\n",
    "***\n",
    "<span style=\"color:gold; font-size:30px\">**Bases de datos - Sondajes**</span>\n",
    "***\n",
    "\n",
    "<span style=\"font-size:20px\"> **Autor: Kevin Alexander Gómez** </span>\n",
    "\n",
    "<span style=\"font-size:16px\"> **Contacto: kevinalexandr19@gmail.com | [Linkedin](https://www.linkedin.com/in/kevin-alexander-g%C3%B3mez-2b0263111/) | [Github](https://github.com/kevinalexandr19)** </span>\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfe9f14-f18f-41a9-acee-6f9377746997",
   "metadata": {
    "tags": []
   },
   "source": [
    "Bienvenido al curso PG102 - Análisis de datos en Geología!!!\n",
    "\n",
    "Vamos a revisar ejemplos de <span style=\"color:gold\">análisis de datos</span> en Geología usando código en Python.\\\n",
    "Es necesario que tengas un conocimiento previo en programación con Python, estadística y geología general.\n",
    "\n",
    "<span style=\"color:lightgreen\"> Este notebook es parte del proyecto [**Python para Geólogos**](https://github.com/kevinalexandr19/manual-python-geologia), y ha sido creado con la finalidad de facilitar el aprendizaje en Python para estudiantes y profesionales en el campo de la Geología. </span>\n",
    "\n",
    "En el siguiente índice, encontrarás los temas que componen este notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77e9c3b-0675-4d04-b5eb-72b7ee2c86e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"font-size:20px\"> **Índice** </span>\n",
    "***\n",
    "- [¿Qué es SQLAlchemy?](#parte-1)\n",
    "- [Creando una base de datos geológicos](#parte-2)\n",
    "- [En conclusión...](#parte-3)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd79e22f-d7c4-4edb-b1b3-48baccbe40de",
   "metadata": {},
   "source": [
    "Antes de empezar tu camino en programación geológica...\\\n",
    "Recuerda que puedes ejecutar un bloque de código usando `Shift` + `Enter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50edd0f5-81ad-4099-96a3-25de702633ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e9eef2-2414-4f5d-9028-11f6ada81dcb",
   "metadata": {},
   "source": [
    "Si por error haces doble clic sobre un bloque de texto (como el que estás leyendo ahora mismo), puedes arreglarlo usando también `Shift` + `Enter`.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4675e8-7806-40c8-adcf-1b129af0bc29",
   "metadata": {},
   "source": [
    "<a id=\"parte-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b4977f-336e-4579-a4cb-b79c32c199cf",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">**¿Qué es SQLAlchemy?**</span>\n",
    "***\n",
    "\n",
    "<span style=\"color:gold\">SQLAlchemy</span> es una librería de Python diseñada para simplificar y automatizar la comunicación entre programas Python y bases de datos.\n",
    "\n",
    "Funciona como un puente entre el lenguaje de programación Python y diversos sistemas de gestión de bases de datos (DBMS), como PostgreSQL, MySQL, SQLite y Oracle. \n",
    "\n",
    "SQLAlchemy ofrece dos modos principales de operación:\n",
    "\n",
    "**1. <span style=\"color:lightgreen\">SQL Expression Language</span>:** \\\n",
    "Permite construir consultas SQL de forma programática, utilizando constructos de Python. Esto significa que puedes crear, leer, actualizar y eliminar datos en tu base de datos directamente a través de tu código Python, sin escribir consultas SQL de forma manual.\n",
    "\n",
    "**2. <span style=\"color:lightgreen\">ORM (Object-Relational Mapping)</span>:** \\\n",
    "Esta capa adicional permite modelar las tablas de tu base de datos como clases Python. Cada clase representa una tabla en tu base de datos, y cada instancia de una clase representa una fila en esa tabla. Esto abstrae aún más el proceso de gestión de datos, permitiéndote trabajar con objetos Python en lugar de consultas SQL directas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea188bfd-6ddb-4a3a-8ba1-3b331f1f09e9",
   "metadata": {},
   "source": [
    "Las **principales ventajas** de usar una base de datos en Geología son:\n",
    "\n",
    "- **<span style=\"color:lightgreen\">Manejo Eficiente de Datos</span>:** \\\n",
    "La capacidad de SQLAlchemy para manejar complejas consultas y transformaciones de datos es invaluable cuando se trabaja con grandes conjuntos de datos geológicos, como mediciones de sensores, registros de perforación o datos de muestreo.\n",
    "\n",
    "- **<span style=\"color:lightgreen\">Abstracción de la Base de Datos</span>:** \\\n",
    "Permite cambiar entre diferentes sistemas de bases de datos con mínimos ajustes en tu código. Esto es especialmente útil en proyectos geológicos donde los requisitos de almacenamiento de datos pueden cambiar con el tiempo.\n",
    "\n",
    "- **<span style=\"color:lightgreen\">Integración con Herramientas de Análisis de Datos</span>:** \\\n",
    "SQLAlchemy se integra bien con otras bibliotecas de análisis de datos en Python, como Pandas y NumPy, facilitando el análisis y la visualización de datos geológicos.\n",
    "\n",
    "Entre las **principales aplicaciones** se tienen:\n",
    "\n",
    "- **<span style=\"color:lightgreen\">Análisis Geoespacial</span>:** \\\n",
    "Al integrarse con bibliotecas de Python especializadas en geoprocesamiento, como GeoPandas, SQLAlchemy puede ser utilizado para gestionar y analizar datos geoespaciales, esenciales en la cartografía geológica, estudios de riesgo sísmico, y exploración de recursos naturales.\n",
    "\n",
    "- **<span style=\"color:lightgreen\">Gestión de Datos de Muestreo</span>:** \\\n",
    "Organizar y acceder a datos de muestras recolectadas en el campo, incluyendo información sobre la ubicación, profundidad, tipo de roca, minerales presentes y otros parámetros relevantes.\n",
    "\n",
    "- **<span style=\"color:lightgreen\">Seguimiento de Proyectos de Exploración</span>:** \\\n",
    "Administrar la información generada en proyectos de exploración, desde datos de perforación hasta análisis geoquímicos y geofísicos, facilitando el acceso y la revisión de datos para la toma de decisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f8ddd-bb94-453e-b4e1-9af218107f9b",
   "metadata": {},
   "source": [
    "<span style=\"color:#43c6ac\">En resumen, SQLAlchemy, al ofrecer una manera flexible y potente de manejar bases de datos desde Python, puede ser una herramienta clave en el arsenal de un geólogo programador, priorizando el análisis y la interpretación de datos geológicos, a la vez que se minimiza el tiempo y esfuerzo dedicado a la gestión de datos.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ddab07-4ac6-4a0d-86c0-961c8fe5b5b4",
   "metadata": {},
   "source": [
    "<a id=\"parte-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75685290-5c33-49e4-9ce1-804ed51310f4",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">**Creando una base de datos geológicos**</span>\n",
    "***\n",
    "\n",
    "Vamos a crear una base de datos usando información de sondajes: Collar, Survey y Assay.\n",
    "\n",
    "Empezaremos cargando los archivos CSV usando Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498b4cfb-83a7-48af-b3ad-baa33a550359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "988984c9-ec6f-48dc-a921-3bd7628155ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Información para enviar a base de datos\n",
    "collar = pd.read_csv(\"files/collar.csv\")\n",
    "survey = pd.read_csv(\"files/survey.csv\")\n",
    "assay = pd.read_csv(\"files/assay.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca5db5c-3254-4752-b45a-fb91fe16dd82",
   "metadata": {},
   "source": [
    "La tabla collar tiene las siguientes columnas:\n",
    "- `ID`: nombre del sondaje\n",
    "- `X`, `Y` y `Z`: coordenadas del collar del sondaje\n",
    "\n",
    "La tabla survey tiene las siguientes columnas:\n",
    "- `ID`: nombre del sondaje\n",
    "- `AT`: profundidad de registro del survey\n",
    "- `AZ`: dirección del sondaje\n",
    "- `DIP`: buzamiento del sondaje\n",
    "\n",
    "La tabla assay tiene las siguientes columnas:\n",
    "- `ID`: nombre del sondaje\n",
    "- `FROM`, `TO`: profundidad inicial y final del tramo\n",
    "- `RECOV`: recuperación del tramo\n",
    "- `CU_pct`: Cu en porcentaje\n",
    "- `AU_gpt`: Au en gramos por tonelada\n",
    "- `AG_gpt`: Ag en gramos por tonelada\n",
    "- `DENSITY`: densidad de la roca en el tramo\n",
    "- `MO_ppm`: Mo en partes por millón\n",
    "- `AS_ppm`: As en partes por millón\n",
    "- `S_pct`: S en porcentaje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5cac6b-97a6-49c4-91dc-a90bf507bab6",
   "metadata": {},
   "source": [
    "A partir de la información recibida, crearemos una base de datos relacional, empezaremos importando la función `create_engine` para inicializar la base de datos en `sqlite`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97731bd8-a763-48a4-91a4-e18da0a4c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a11e49-8387-4f5a-b043-0110847f9454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establece el tipo de base de datos en sqlite\n",
    "engine = create_engine(\"sqlite:///files/sondajes.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f6458-d990-4714-b997-3d08856a86fe",
   "metadata": {},
   "source": [
    "Ahora, crearemos un modelo declarativo basándonos en la estructura de las tablas collar, survey y assay.\n",
    "\n",
    "Usaremos el módulo `orm` de SQLAlchemy para crear este modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e17f347-0b59-4b06-9acb-6bb12a8cc61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Float, ForeignKey, MetaData, Table\n",
    "from sqlalchemy.orm import declarative_base, relationship, sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee4e7cf-1dc6-48e8-84df-580c44d41052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una conexión a la base de datos \n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a03a63-64ce-4092-b946-0276f3dc0214",
   "metadata": {},
   "source": [
    "Ahora, crearemos el modelo declarativo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a0027bd-0dc8-4b9b-a588-4fd21e1bb6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una instancia del modelo declarativo\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74fe3b37-39fa-4fd6-b2c6-4078d1fec662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estructura de la tabla collar\n",
    "class Collar(Base):\n",
    "    __tablename__ = \"collar\" # Nombre de la tabla\n",
    "    id = Column(String, primary_key=True) # Llave primaria\n",
    "\n",
    "    # Columnas de datos\n",
    "    collar_x = Column(Float)\n",
    "    collar_y = Column(Float)\n",
    "    collar_z = Column(Float)\n",
    "    \n",
    "    # Relación (ORM para consultas)\n",
    "    surveys = relationship(\"Survey\", back_populates=\"collars\")\n",
    "    assays = relationship(\"Assay\", back_populates=\"collars\")\n",
    "\n",
    "# Estructura de la tabla survey\n",
    "class Survey(Base):\n",
    "    __tablename__ = \"survey\" # Nombre de la tabla\n",
    "    survey_name = Column(Integer, primary_key=True) # Llave primaria\n",
    "    id = Column(String, ForeignKey(\"collar.id\"))    # Llave foránea\n",
    "\n",
    "    # Columnas de datos\n",
    "    depth = Column(Float)\n",
    "    direction = Column(Float)\n",
    "    angle = Column(Float)\n",
    "    \n",
    "    # Relación inversa (ORM)\n",
    "    collars = relationship(\"Collar\", back_populates=\"surveys\")\n",
    "\n",
    "# Estructura de la tabla assay\n",
    "class Assay(Base):\n",
    "    __tablename__ = \"assay\" # Nombre de la tabla\n",
    "    assay_name = Column(Integer, primary_key=True) # Llave primaria\n",
    "    id = Column(String, ForeignKey(\"collar.id\"))   # Llave foránea\n",
    "\n",
    "    # Columnas de datos\n",
    "    from_depth = Column(Float)\n",
    "    to_depth = Column(Float)\n",
    "    recov = Column(Float)\n",
    "    Cu = Column(Float)\n",
    "    Au = Column(Float)\n",
    "    Ag = Column(Float)\n",
    "    density = Column(Float)\n",
    "    Mo = Column(Float)\n",
    "    As = Column(Float)\n",
    "    S = Column(Float)\n",
    "    \n",
    "    # Relación inversa (ORM)\n",
    "    collars = relationship(\"Collar\", back_populates=\"assays\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a50561e-b2a8-42bb-918b-e3c28af010b2",
   "metadata": {},
   "source": [
    "Ahora, implementaremos la estructura en la base de datos usando el método `metadata.create_all`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a511b3c0-db79-4c52-ab74-ae4b40d26a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando las tablas en la base de datos, si aún no existen\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7bffce-623f-4a34-8753-1746a9f599b0",
   "metadata": {},
   "source": [
    "Una vez creado el modelo declarativo, llenaremos la base de datos con la información de sondajes:\n",
    "> Para añadir una fila a la base de datos (a través de la sesión/conexión), usaremos el método `add`.\\\n",
    "> Para guardar los cambios, usaremos el método `commit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857dd407-d28f-4b34-8645-540c8cbf3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar datos de collar\n",
    "for index, row in collar.iterrows():\n",
    "    collar_row = Collar(id=row[\"ID\"],\n",
    "                        collar_x=row[\"X\"],\n",
    "                        collar_y=row[\"Y\"],\n",
    "                        collar_z=row[\"Z\"]\n",
    "                       )\n",
    "    # Agregar fila a la base de datos\n",
    "    session.add(collar_row)\n",
    "\n",
    "# Agregar datos de survey\n",
    "for index, row in survey.iterrows():\n",
    "    survey_row = Survey(id=row[\"ID\"],\n",
    "                        depth=row[\"AT\"],\n",
    "                        direction=row[\"AZ\"],\n",
    "                        angle=row[\"DIP\"]\n",
    "                       )\n",
    "    # Agregar fila a la base de datos\n",
    "    session.add(survey_row)\n",
    "\n",
    "# Agregar datos de assay\n",
    "for index, row in assay.iterrows():\n",
    "    assay_row = Assay(id=row[\"ID\"],\n",
    "                      from_depth=row[\"FROM\"],\n",
    "                      to_depth=row[\"TO\"],\n",
    "                      recov=row[\"RECOV\"],\n",
    "                      Cu=row[\"CU_pct\"],\n",
    "                      Au=row[\"AU_gpt\"],\n",
    "                      Ag=row[\"AG_gpt\"],\n",
    "                      density=row[\"DENSITY\"],\n",
    "                      Mo=row[\"MO_ppm\"],\n",
    "                      As=row[\"AS_ppm\"],\n",
    "                      S=row[\"S_pct\"]\n",
    "                     )\n",
    "    # Agregar fila a la base de datos\n",
    "    session.add(assay_row)\n",
    "\n",
    "# Guardar los cambios\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451b48c-f7de-4986-984d-0b45e786786b",
   "metadata": {},
   "source": [
    "Ahora que hemos creado la base de datos, revisaremos el contenido usando el método `query` y `all`:\n",
    "> El método `query` formula una consulta SQL sobre uno de los modelos (Collar, Survey, Assay).\\\n",
    "> El método `all` selecciona todos los elementos de la consulta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7c61ffb-f388-450b-8272-282581ef2fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos en la tabla Collar:\n",
      "ID: DH001, X: 426.155999999959, Y: 1220.25, Z: 298.1178610000002\n",
      "ID: DH002, X: 424.56199999997625, Y: 1219.3120000000345, Z: 294.6257320000004\n",
      "ID: DH003, X: 488.5, Y: 970.375, Z: 249.3986520000003\n",
      "ID: DH004, X: 431.280999999959, Y: 830.3120000000345, Z: 274.1379880000004\n",
      "ID: DH005, X: 519.5, Y: 675.875, Z: 197.79505400000016\n",
      "ID: DH006, X: 521.9679999999935, Y: 996.469000000041, Z: 211.20900100000017\n",
      "ID: DH007, X: 524.530999999959, Y: 999.9060000000172, Z: 214.4400910000004\n",
      "ID: DH008, X: 688.75, Y: 430.81200000003446, Z: 219.50394700000012\n",
      "ID: DH009, X: 680.25, Y: 511.844000000041, Z: 220.6613110000003\n",
      "ID: DH010, X: 655.155999999959, Y: 633.344000000041, Z: 219.01803900000004\n"
     ]
    }
   ],
   "source": [
    "# Verificación de los datos en la tabla Collar\n",
    "collar_table = session.query(Collar).all()\n",
    "\n",
    "# Mostramos las 10 primeras filas\n",
    "print(\"Datos en la tabla Collar:\")\n",
    "for row in collar_table[:10]:\n",
    "    print(f\"ID: {row.id}, X: {row.collar_x}, Y: {row.collar_y}, Z: {row.collar_z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ba8b386-906e-46ad-b369-a733564ba9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos en la tabla Survey:\n",
      "Survey Name: 1, ID: DH001\n",
      "        Depth: 0.0, Direction: 90.5, Angle: 50.0\n",
      "Survey Name: 2, ID: DH001\n",
      "        Depth: 31.0, Direction: 90.5, Angle: 50.0\n",
      "Survey Name: 3, ID: DH001\n",
      "        Depth: 198.050003, Direction: 90.5, Angle: 50.0\n",
      "Survey Name: 4, ID: DH002\n",
      "        Depth: 0.0, Direction: 271.5, Angle: 45.0\n",
      "Survey Name: 5, ID: DH002\n",
      "        Depth: 31.0, Direction: 271.5, Angle: 45.0\n",
      "Survey Name: 6, ID: DH002\n",
      "        Depth: 222.100006, Direction: 271.5, Angle: 45.0\n",
      "Survey Name: 7, ID: DH003\n",
      "        Depth: 0.0, Direction: 271.5, Angle: 44.0\n",
      "Survey Name: 8, ID: DH003\n",
      "        Depth: 30.0, Direction: 271.5, Angle: 44.0\n",
      "Survey Name: 9, ID: DH003\n",
      "        Depth: 208.199997, Direction: 271.5, Angle: 45.0\n",
      "Survey Name: 10, ID: DH004\n",
      "        Depth: 0.0, Direction: 265.5, Angle: 45.0\n"
     ]
    }
   ],
   "source": [
    "# Verificación de los datos en la tabla Survey\n",
    "survey_table = session.query(Survey).all()\n",
    "\n",
    "# Mostramos las 10 primeras filas\n",
    "print(\"Datos en la tabla Survey:\")\n",
    "for row in survey_table[:10]:\n",
    "    print(f\"\"\"Survey Name: {row.survey_name}, ID: {row.id}\n",
    "        Depth: {row.depth}, Direction: {row.direction}, Angle: {row.angle}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06caa0-4998-4e6a-abd9-c2221cf8b972",
   "metadata": {},
   "source": [
    "Si queremos limitar el número de filas a seleccionar, también podemos usar el método `limit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e50c1ba7-64a9-4e66-87a3-487c6b749f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos en la tabla Assay:\n",
      "Assay Name: 1, ID: DH001\n",
      "        FROM: 0.0, TO: 2.0,\n",
      "        Cu: 0.79, Au: 1.75, Ag: 6.35, Density: None, Mo: 10.0, As: 26.3, S: 0.0\n",
      "Assay Name: 2, ID: DH001\n",
      "        FROM: 2.0, TO: 4.0,\n",
      "        Cu: 0.83, Au: 1.73, Ag: 5.2, Density: None, Mo: 12.2, As: 31.0, S: 0.0\n",
      "Assay Name: 3, ID: DH001\n",
      "        FROM: 4.0, TO: 6.0,\n",
      "        Cu: 0.84, Au: 6.0, Ag: 5.75, Density: None, Mo: 24.8, As: 32.5, S: 0.0\n",
      "Assay Name: 4, ID: DH001\n",
      "        FROM: 6.0, TO: 8.0,\n",
      "        Cu: 0.83, Au: 2.56, Ag: 2.85, Density: 2.32, Mo: 15.7, As: 13.9, S: 0.2\n",
      "Assay Name: 5, ID: DH001\n",
      "        FROM: 8.0, TO: 10.0,\n",
      "        Cu: 0.97, Au: 1.53, Ag: 2.9, Density: 2.98, Mo: 14.8, As: 15.5, S: 0.5\n",
      "Assay Name: 6, ID: DH001\n",
      "        FROM: 10.0, TO: 12.0,\n",
      "        Cu: 1.48, Au: 2.25, Ag: 3.35, Density: 2.52, Mo: 39.2, As: 20.2, S: 1.0\n",
      "Assay Name: 7, ID: DH001\n",
      "        FROM: 12.0, TO: 14.0,\n",
      "        Cu: 1.03, Au: 2.24, Ag: 3.9, Density: 2.61, Mo: 295.0, As: 31.3, S: 1.5\n",
      "Assay Name: 8, ID: DH001\n",
      "        FROM: 14.0, TO: 16.0,\n",
      "        Cu: 0.38, Au: 0.69, Ag: 1.8, Density: 2.67, Mo: 210.2, As: 29.1, S: 1.2\n",
      "Assay Name: 9, ID: DH001\n",
      "        FROM: 16.0, TO: 18.0,\n",
      "        Cu: 0.94, Au: 1.76, Ag: 2.35, Density: 2.74, Mo: 249.9, As: 26.6, S: 1.7\n",
      "Assay Name: 10, ID: DH001\n",
      "        FROM: 18.0, TO: 20.0,\n",
      "        Cu: 1.66, Au: 1.48, Ag: 3.75, Density: 2.96, Mo: 26.1, As: 9.1, S: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Verificación de los datos en la tabla Assay\n",
    "assay_table = session.query(Assay).limit(10)\n",
    "\n",
    "# Mostramos las 10 primeras filas\n",
    "print(\"Datos en la tabla Assay:\")\n",
    "for row in assay_table:\n",
    "    print(f\"\"\"Assay Name: {row.assay_name}, ID: {row.id}\n",
    "        FROM: {row.from_depth}, TO: {row.to_depth},\n",
    "        Cu: {row.Cu}, Au: {row.Au}, Ag: {row.Ag}, Density: {row.density}, Mo: {row.Mo}, As: {row.As}, S: {row.S}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e36427-528c-4509-8f1f-d6be79d5783a",
   "metadata": {},
   "source": [
    "<a id=\"parte-3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdadeae-24d2-4e49-a9c9-6962f1f3d22d",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightgreen\">**En conclusión...**</span>\n",
    "***\n",
    "\n",
    "Manejar bases de datos con SQLAlchemy permite organizar, acceder y manipular grandes volúmenes de datos de manera estructurada y eficiente, lo cual es esencial para el análisis de datos en Geología.\n",
    "\n",
    "La integración de SQLAlchemy con otras librerías de Python posibilita realizar análisis complejos y visualizaciones de datos, ayudando a la interpretación y toma de decisiones en Geología.\n",
    "\n",
    "<span style=\"color:#43c6ac\">El almacenamiento de datos de sondajes en bases de datos facilita la gestión centralizada, acceso rápido y análisis detallado de la información geológica crítica, mejorando significativamente la eficiencia en la exploración y evaluación de recursos</span>.\n",
    "\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
